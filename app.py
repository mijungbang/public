import streamlit as st
import pandas as pd
import requests
import re
from bs4 import BeautifulSoup
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def krx_listingcompany_normal(fromDate, toDate):
    url = "https://kind.krx.co.kr/listinvstg/listingcompany.do"
    headers = {
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "User-Agent": "Mozilla/5.0",
        "Referer": "https://kind.krx.co.kr/listinvstg/listingcompany.do?method=searchListingTypeMain",
        "X-Requested-With": "XMLHttpRequest",
        "Origin": "https://kind.krx.co.kr",
    }
    data = {
        "method": "searchListingTypeSub",
        "currentPageSize": "100",
        "pageIndex": "1",
        "orderMode": "1",
        "orderStat": "D",
        "repIsuSrtCd": "",
        "isurCd": "",
        "forward": "listingtype_sub",
        "listTypeArrStr": "01|02|03|04|05|",
        "secuGrpArrStr": "0|ST|FS|MF|SC|RT|DR|",
        "secuGrpArr": ["0", "ST|FS", "MF|SC|RT", "DR"],
        "listTypeArr": ["01", "02", "03", "04", "05"],
        "fromDate": fromDate,
        "toDate": toDate,
    }
    try:
        response = requests.post(url, headers=headers, data=data, verify=False, timeout=10)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, "html.parser")
        table = soup.find("table", class_="list type-00 tmt30")
        columns = ["ë‹¨ì¶•ì½”ë“œ", "íšŒì‚¬ëª…", "ìƒì¥ì¼", "ìƒì¥ìœ í˜•", "ì¦ê¶Œêµ¬ë¶„", "ì—…ì¢…", "êµ­ì ", "ìƒì¥ì£¼ì„ ì¸/ì§€ì •ìë¬¸ì¸"]
        data_rows = []
        if table and table.tbody:
            for row in table.tbody.find_all("tr"):
                cells = row.find_all("td")
                onclick = row.get("onclick", "")
                match = re.search(r"fnDetailView\('(\d+)'", onclick)
                short_code = match.group(1) if match else ""
                row_data = [short_code]
                for i, cell in enumerate(cells[:len(columns) - 1]):
                    if i == 0:
                        row_data.append(cell.get("title", "").strip())
                    else:
                        row_data.append(cell.get_text(strip=True))
                data_rows.append(row_data)
        return pd.DataFrame(data_rows, columns=columns)
    except Exception as e:
        return pd.DataFrame(columns=["ë‹¨ì¶•ì½”ë“œ", "íšŒì‚¬ëª…", "ìƒì¥ì¼", "ìƒì¥ìœ í˜•", "ì¦ê¶Œêµ¬ë¶„", "ì—…ì¢…", "êµ­ì ", "ìƒì¥ì£¼ì„ ì¸/ì§€ì •ìë¬¸ì¸"])

def get_nextrade_filtered_symbols(trade_date):
    url = "https://www.nextrade.co.kr/brdinfoTime/brdinfoTimeList.do"
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": "https://www.nextrade.co.kr/menu/transactionStatusMain/menuList.do",
        "Origin": "https://www.nextrade.co.kr",
        "X-Requested-With": "XMLHttpRequest",
        "Content-Type": "application/x-www-form-urlencoded",
    }
    payload = {
        "_search": "false",
        "nd": str(int(pd.Timestamp.now().timestamp() * 1000)),
        "pageUnit": "900",
        "pageIndex": "1",
        "sidx": "",
        "sord": "asc",
        "scAggDd": trade_date,
        "scMktId": "",
        "searchKeyword": ""
    }
    try:
        response = requests.post(url, headers=headers, data=payload, verify=False, timeout=10)
        response.encoding = 'utf-8'
        result = response.json()
        raw_data = result.get('brdinfoTimeList', [])
        keep_keys = ["aggDd", "mktNm", "isuCd", "isuSrdCd", "isuAbwdNm", "cptrTrdPmsnCdNm", "trdIpsbRsn"]
        filtered_data = [{k: item.get(k, None) for k in keep_keys} for item in raw_data]
        if not filtered_data:
            return pd.DataFrame(columns=["ì§‘ê³„ì¼", "ì‹œì¥êµ¬ë¶„", "ì¢…ëª©ì½”ë“œ", "ë‹¨ì¶•ì½”ë“œ", "ì¢…ëª©ëª…", "ê±°ë˜ê°€ëŠ¥ì‹œì¥", "ê±°ë˜ë¶ˆê°€ì‚¬ìœ "])
        df = pd.DataFrame(filtered_data)
        df.columns = ["ì§‘ê³„ì¼", "ì‹œì¥êµ¬ë¶„", "ì¢…ëª©ì½”ë“œ", "ë‹¨ì¶•ì½”ë“œ", "ì¢…ëª©ëª…", "ê±°ë˜ê°€ëŠ¥ì‹œì¥", "ê±°ë˜ë¶ˆê°€ì‚¬ìœ "]
        df["ë‹¨ì¶•ì½”ë“œ"] = df["ë‹¨ì¶•ì½”ë“œ"].str[1:]
        return df[(df["ê±°ë˜ê°€ëŠ¥ì‹œì¥"] != "ê±°ë˜ë¶ˆê°€") | (df["ê±°ë˜ë¶ˆê°€ì‚¬ìœ "] == "ê±°ë˜ì •ì§€")]
    except Exception as e:
        return pd.DataFrame(columns=["ì§‘ê³„ì¼", "ì‹œì¥êµ¬ë¶„", "ì¢…ëª©ì½”ë“œ", "ë‹¨ì¶•ì½”ë“œ", "ì¢…ëª©ëª…", "ê±°ë˜ê°€ëŠ¥ì‹œì¥", "ê±°ë˜ë¶ˆê°€ì‚¬ìœ "])

def get_krx_market_price_info(trdDd):
    url = "http://data.krx.co.kr/comm/bldAttendant/getJsonData.cmd"
    headers = {
        "Referer": "http://data.krx.co.kr/contents/MDC/MDI/mdiLoader/index.cmd?menuId=MDC0201020202",
        "User-Agent": "Mozilla/5.0"
    }
    payload = {
        "bld": "dbms/MDC/STAT/standard/MDCSTAT01501",
        "locale": "ko_KR",
        "mktId": "ALL",
        "trdDd": trdDd,
        "share": "1",
        "money": "1",
        "csvxls_isNo": "false"
    }
    try:
        response = requests.post(url, headers=headers, data=payload, timeout=10)
        data = response.json()
        df = pd.DataFrame(data['OutBlock_1'])
        df = df.rename(columns={
            "ISU_SRT_CD": "ë‹¨ì¶•ì½”ë“œ",
            "ISU_ABBRV": "ì¢…ëª©ëª…",
            "MKT_NM": "ì‹œì¥êµ¬ë¶„",
            "MKTCAP": "ì‹œê°€ì´ì•¡"
        })
        df = df[df["ì‹œì¥êµ¬ë¶„"] != "KONEX"]
        df["ì‹œì¥êµ¬ë¶„"] = df["ì‹œì¥êµ¬ë¶„"].str.replace("KOSDAQ GLOBAL", "KOSDAQ")
        df["ì‹œê°€ì´ì•¡"] = df["ì‹œê°€ì´ì•¡"].str.replace("-", "0").str.replace(",", "").astype(float)
        return df[["ë‹¨ì¶•ì½”ë“œ", "ì¢…ëª©ëª…", "ì‹œì¥êµ¬ë¶„", "ì‹œê°€ì´ì•¡"]]
    except Exception as e:
        return pd.DataFrame(columns=["ë‹¨ì¶•ì½”ë“œ", "ì¢…ëª©ëª…", "ì‹œì¥êµ¬ë¶„", "ì‹œê°€ì´ì•¡"])

st.set_page_config(page_title="ì‹ ê·œìƒì¥ ì‹œê°€ì´ì•¡ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ“ˆ ì‹ ê·œìƒì¥ ì¢…ëª© ì‹œê°€ì´ì•¡ í¸ì… ë¶„ì„ê¸°")

col1, col2 = st.columns(2)
from_date = col1.date_input("ì¡°íšŒ ì‹œì‘ì¼", pd.to_datetime("today") - pd.Timedelta(days=5))
to_date = col2.date_input("ì¡°íšŒ ì¢…ë£Œì¼", pd.to_datetime("today"))

if from_date > to_date:
    st.error("ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ë’¤ì— ìˆìŠµë‹ˆë‹¤.")
    st.stop()

if st.button("ğŸ” ì‹ ê·œìƒì¥ ì¢…ëª© ë¶ˆëŸ¬ì˜¤ê¸°"):
    listing = krx_listingcompany_normal(from_date.strftime("%Y-%m-%d"), to_date.strftime("%Y-%m-%d"))
    if listing.empty:
        st.warning("ì¡°íšŒëœ ì‹ ê·œìƒì¥ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    st.dataframe(listing, use_container_width=True)
    target_name = st.selectbox("ë¶„ì„í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”", listing["íšŒì‚¬ëª…"])
    if target_name:
        target_date = listing[listing["íšŒì‚¬ëª…"] == target_name]["ìƒì¥ì¼"].values[0]
        df_filtered = get_nextrade_filtered_symbols(target_date)
        market_cap = get_krx_market_price_info(target_date)

        if target_name not in market_cap["ì¢…ëª©ëª…"].values:
            st.warning("í•´ë‹¹ ì¢…ëª©ì€ KRX ì‹œê°€ì´ì•¡ ë°ì´í„°ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            st.stop()

        if target_name not in df_filtered["ì¢…ëª©ëª…"].values:
            st.warning("í•´ë‹¹ ì¢…ëª©ì€ ë„¥ìŠ¤íŠ¸ë ˆì´ë“œ ê±°ë˜ ê°€ëŠ¥ ì¢…ëª© ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        df_merged = df_filtered.merge(market_cap, on=["ë‹¨ì¶•ì½”ë“œ", "ì¢…ëª©ëª…", "ì‹œì¥êµ¬ë¶„"], how="left")
        row = market_cap[market_cap["ì¢…ëª©ëª…"] == target_name].iloc[0]
        target_market = row["ì‹œì¥êµ¬ë¶„"]
        target_ticker = row["ë‹¨ì¶•ì½”ë“œ"]
        target_marketcap = row["ì‹œê°€ì´ì•¡"]

        market_df = df_merged[df_merged["ì‹œì¥êµ¬ë¶„"] == target_market].dropna(subset=["ì‹œê°€ì´ì•¡"]).copy()
        market_df = market_df.sort_values("ì‹œê°€ì´ì•¡", ascending=False).reset_index(drop=True)

        rank = (market_df["ì‹œê°€ì´ì•¡"] > target_marketcap).sum() + 1
        total = len(market_df)
        rank_cutoff = total // 2
        percent_rank = (rank - 1) / (total - 1) if total > 1 else 0
        marketcap_cutoff = market_df.iloc[rank_cutoff - 1]["ì‹œê°€ì´ì•¡"] if rank_cutoff - 1 < total else None
        included = "í¸ì…" if rank <= rank_cutoff else "ë¯¸í¸ì…"

        summary_df = pd.DataFrame([{
            "ìƒì¥ì¼": target_date,
            "ì¢…ëª©ì½”ë“œ": target_ticker,
            "ì¢…ëª©ëª…": target_name,
            "ì‹œì¥êµ¬ë¶„": target_market,
            "ì‹œê°€ì´ì•¡": target_marketcap,
            "í¸ì…ê¸°ì¤€ ì‹œê°€ì´ì•¡": marketcap_cutoff,
            "ì‹œê°€ì´ì•¡ ìˆœìœ„": rank,
            "í¸ì…ê¸°ì¤€ ìˆœìœ„": rank_cutoff,
            "Percent Rank": percent_rank,
            "í¸ì…ì—¬ë¶€": included
        }])

        st.dataframe(summary_df, use_container_width=True)
